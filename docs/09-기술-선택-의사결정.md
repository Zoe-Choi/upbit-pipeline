# 기술 스택 선택 의사결정 과정

> 이 문서는 실시간 데이터 파이프라인을 구축하면서 각 오픈소스 기술을 선택한 이유와 의사결정 과정을 정리합니다.

## 목차

1. [프로젝트 요구사항](#프로젝트-요구사항)
2. [메시지 브로커: Apache Kafka](#1-메시지-브로커-apache-kafka)
3. [스트림 처리: Apache Flink](#2-스트림-처리-apache-flink)
4. [데이터 레이크: Apache Paimon + MinIO](#3-데이터-레이크-apache-paimon--minio)
5. [실시간 분석 DB: ClickHouse](#4-실시간-분석-db-clickhouse)
6. [시각화: Grafana](#5-시각화-grafana)
7. [최종 아키텍처](#최종-아키텍처)

---

## 프로젝트 요구사항

### 비즈니스 요구사항

| 요구사항 | 상세 |
|----------|------|
| **데이터 소스** | 업비트 WebSocket API (실시간 시세, 체결) |
| **처리량** | 초당 수천 건의 이벤트 |
| **지연시간** | 1초 이내 실시간 처리 |
| **데이터 보존** | 장기 저장 (ML 학습용) + 단기 저장 (실시간 분석) |
| **분석** | 분석가가 SQL로 실시간 조회 가능해야 함 |
| **시각화** | 실시간 대시보드 + 알림 |

### 기술적 제약사항

| 제약 | 내용 |
|------|------|
| **환경** | M1 Pro MacBook (16GB RAM) |
| **목표** | 로컬에서 실제 운영 환경과 유사한 분산 시스템 구현 |
| **학습** | 분산 시스템, 샤딩, 레플리케이션 개념 실습 |

---

## 1. 메시지 브로커: Apache Kafka

### 문제 정의

> "초당 수천 건의 WebSocket 이벤트를 안정적으로 수집하고, 여러 Consumer가 독립적으로 소비할 수 있어야 한다"

### 비교 대상

| 기술 | 장점 | 단점 |
|------|------|------|
| **Apache Kafka** | 업계 표준, 고가용성, 파티셔닝, 리플레이 가능 | 리소스 사용량 높음, 운영 복잡도 |
| **RabbitMQ** | 낮은 리소스, 다양한 라우팅, 간단한 설정 | 메시지 리플레이 어려움, 대용량에 부적합 |
| **Redis Streams** | 매우 빠름, 간단함 | 영속성 보장 약함, 분산 처리 한계 |
| **Apache Pulsar** | 다중 테넌시, 계층화 스토리지 | 생태계 작음, 학습 자료 부족 |

### 의사결정 과정

1. **초기 고민**: RabbitMQ가 리소스를 적게 쓰니까 16GB 환경에 적합하지 않을까?

2. **재고려 포인트**:
   - Flink와의 연동은 Kafka가 가장 성숙함
   - 메시지 리플레이(재처리) 필요 - 장애 발생 시 과거 데이터부터 다시 처리
   - 파티셔닝으로 병렬 처리 가능
   - 실제 현업에서 가장 많이 사용되는 조합

3. **KRaft vs ZooKeeper**:
   - ZooKeeper: 별도 클러스터 필요, 추가 리소스 소모
   - KRaft: Kafka 3.x부터 지원, 메타데이터 자체 관리
   - **선택: KRaft** (리소스 절약 + 미래 표준)

### 최종 결정

```
✅ Apache Kafka (KRaft 모드) - 3 브로커 클러스터
```

**이유**:
- Flink 네이티브 연동 (Kafka Connector가 가장 성숙)
- 파티션 기반 병렬 처리로 처리량 확장 용이
- Consumer Group으로 여러 시스템이 독립적 소비 가능
- 메시지 리플레이로 장애 복구 가능
- KRaft 모드로 ZooKeeper 없이 운영 (리소스 절약)

### 구성

```yaml
# 3-broker 클러스터 구성
kafka-1: controller + broker (512MB)
kafka-2: controller + broker (512MB)
kafka-3: controller + broker (512MB)
# 총 1.5GB
```

---

## 2. 스트림 처리: Apache Flink

### 문제 정의

> "Kafka에서 들어오는 실시간 데이터를 변환하고, 정확히 한 번(Exactly-once) 처리 보장이 필요하다"

### 비교 대상

| 기술 | 장점 | 단점 |
|------|------|------|
| **Apache Flink** | Exactly-once 보장, 낮은 레이턴시, 상태 관리 우수 | 리소스 사용량 높음, 학습 곡선 |
| **Apache Spark Streaming** | 배치와 통합 용이, 넓은 생태계 | 마이크로 배치 방식 (레이턴시 높음) |
| **Kafka Streams** | 별도 클러스터 불필요, 간단함 | 복잡한 처리 한계, Kafka에 종속 |
| **Apache Storm** | 매우 낮은 레이턴시 | 오래됨, Exactly-once 보장 어려움 |

### 의사결정 과정

1. **초기 고민**: Kafka Streams가 별도 클러스터 없이 동작하니까 리소스 절약되지 않을까?

2. **재고려 포인트**:
   - Paimon은 Flink 네이티브 - 다른 엔진보다 연동이 훨씬 자연스러움
   - 복잡한 윈도우 연산, 상태 관리가 필요할 수 있음
   - Flink SQL로 코드 없이 파이프라인 정의 가능
   - 체크포인팅으로 장애 복구 보장

3. **Spark Streaming 제외 이유**:
   - 마이크로 배치 방식으로 최소 수백 ms 지연
   - 진정한 실시간이 아님

### 최종 결정

```
✅ Apache Flink - 1 JobManager + 2 TaskManager (병렬도 3)
```

**이유**:
- Paimon과 네이티브 통합 (같은 Apache 생태계)
- Exactly-once 시맨틱으로 데이터 정합성 보장
- Flink SQL로 선언적 파이프라인 정의
- 체크포인팅 + RocksDB로 대용량 상태 관리
- 낮은 레이턴시 (밀리초 단위)

### 구성 및 최적화

```yaml
# 초기 구성
JobManager: 1개 (768MB)
TaskManager: 2개 (1.3GB × 2 = 2.6GB)
병렬도: 2 (TaskManager 수와 동일)

# 최적화 후
병렬도: 3 (Kafka 파티션 수와 맞춤)
슬롯: TaskManager당 2개 (총 4슬롯)
체크포인트: 30초 간격, RocksDB 상태 백엔드
재시작 전략: exponential-delay (실패 시 점진적 대기)
```

**최적화 이유**:
- Kafka 파티션 3개 = Flink 병렬도 3 → 최대 병렬 처리
- RocksDB: 메모리 절약하면서 대용량 상태 저장 가능
- exponential-delay: 일시적 장애 시 무한 재시작 방지

---

## 3. 데이터 레이크: Apache Paimon + MinIO

### 문제 정의

> "실시간 스트리밍 데이터를 장기 저장하고, 나중에 배치로 ML 학습에 활용해야 한다"

### 테이블 포맷 비교

| 기술 | 장점 | 단점 |
|------|------|------|
| **Apache Paimon** | Flink 네이티브, 실시간 업데이트, ACID | 생태계 작음, Trino 연동 제한적 |
| **Apache Iceberg** | 넓은 생태계, Trino/Spark 지원 우수 | Flink 연동은 Paimon보다 복잡 |
| **Delta Lake** | Spark와 최적 통합 | Databricks 종속성, Flink 지원 미흡 |
| **Apache Hudi** | Upsert 특화, CDC 지원 | 설정 복잡, 리소스 사용량 높음 |

### 오브젝트 스토리지 비교

| 기술 | 장점 | 단점 |
|------|------|------|
| **MinIO** | S3 100% 호환, 로컬 개발 최적 | 운영 환경에서는 AWS S3가 더 적합 |
| **AWS S3** | 무제한 확장, 관리 불필요 | 비용, 로컬 개발 불편 |
| **HDFS** | 빅데이터 표준 | 로컬에서 운영 어려움, 리소스 많이 필요 |

### 의사결정 과정

1. **초기 고민**: Iceberg가 생태계가 더 넓으니까 그게 낫지 않을까?

2. **재고려 포인트**:
   - Flink를 메인 엔진으로 선택함 → Paimon이 네이티브 연동
   - Paimon은 Flink 커뮤니티에서 개발 (최적화 보장)
   - 스트리밍 upsert가 자연스러움
   - 체크포인트와 동기화되어 Exactly-once 보장

3. **MinIO 선택 이유**:
   - AWS S3와 100% 호환 API
   - 나중에 클라우드 이전 시 코드 변경 최소화
   - 분산 모드로 고가용성 실습 가능

### 최종 결정

```
✅ Apache Paimon + MinIO (분산 모드 4노드)
```

**이유**:
- Flink 네이티브 통합으로 개발 생산성 향상
- 스트리밍 → 레이크 저장이 단일 파이프라인으로 완성
- MinIO 분산 모드로 고가용성 + Erasure Coding 실습
- S3 호환으로 클라우드 마이그레이션 용이

### 구성

```yaml
# MinIO 분산 클러스터
minio-1 ~ minio-4: 4노드 (각 256MB)
# Erasure Coding: 1노드 장애에도 데이터 유지

# Paimon 설정
catalog-type: filesystem
warehouse: s3://paimon/
checkpoint-interval: 30s
changelog-producer: input  # 변경 이력 추적
```

### 트러블슈팅

**문제**: Flink에서 MinIO 연결 시 S3 플러그인 오류

```
UnsupportedFileSystemSchemeException: Could not find a file system 
implementation for scheme 's3'
```

**해결**: 커스텀 Flink Docker 이미지 빌드

```dockerfile
# Flink에 필요한 JAR 추가
COPY flink-s3-fs-hadoop.jar /opt/flink/plugins/s3-fs-hadoop/
COPY hadoop-aws.jar /opt/flink/lib/
COPY aws-java-sdk-bundle.jar /opt/flink/lib/
```

**교훈**: Flink S3 플러그인은 `/opt/flink/plugins/` 디렉토리에 별도 배치해야 함

---

## 4. 실시간 분석 DB: ClickHouse

### 문제 정의

> "분석가가 SQL로 실시간 데이터를 빠르게 조회하고, 대시보드에서 시각화해야 한다"

### 비교 대상

| 기술 | 장점 | 단점 |
|------|------|------|
| **ClickHouse** | 초고속 분석 쿼리, 컬럼 기반, Kafka 통합 | 트랜잭션 미지원, 업데이트 비효율 |
| **Apache Druid** | 실시간 수집, 롤업 집계 | 설정 복잡, 리소스 많이 필요 |
| **TimescaleDB** | PostgreSQL 호환, 시계열 특화 | 대용량에서 ClickHouse보다 느림 |
| **Elasticsearch** | 풀텍스트 검색, 유연한 스키마 | 집계 쿼리 느림, 메모리 많이 사용 |
| **Trino** | 다양한 소스 연결, 페더레이션 | 저장소 없음, 매번 스캔 필요 |

### 의사결정 과정

1. **초기 질문**: Paimon 데이터를 Trino로 직접 쿼리하면 안 되나?

2. **분석**:
   - Trino: 매 쿼리마다 MinIO에서 파일 스캔 → 느림
   - ClickHouse: 데이터를 자체 저장 → 인덱스 활용 가능 → 빠름
   - 실시간 대시보드에는 밀리초 단위 응답 필요

3. **역할 분담 결론**:
   ```
   Paimon (MinIO)    → 장기 저장, ML 학습 데이터
   ClickHouse        → 실시간 분석, 대시보드
   ```

4. **ClickHouse 선택 이유**:
   - Kafka Engine으로 직접 메시지 소비 가능
   - 컬럼 기반 압축으로 스토리지 효율적
   - TTL로 자동 데이터 만료 (7일)
   - 분산 클러스터 지원 (샤딩, 레플리케이션)

### 최종 결정

```
✅ ClickHouse (2-shard 클러스터) + ClickHouse Keeper
```

**이유**:
- Kafka Engine으로 ETL 없이 직접 수집
- 컬럼 기반 저장으로 분석 쿼리 초고속
- TTL로 7일 후 자동 삭제 (스토리지 관리)
- 샤딩으로 분산 처리 개념 실습

### 구성

```yaml
# ClickHouse 클러스터
clickhouse-1: shard 1 (1.5GB)
clickhouse-2: shard 2 (1.5GB)
clickhouse-keeper: 코디네이터 (256MB)

# 테이블 구조
ticker_kafka   → Kafka Engine (메시지 소비)
ticker_local   → MergeTree (로컬 저장, TTL 7일)
ticker         → Distributed (샤드 통합 조회)
```

### 트러블슈팅

**문제 1**: ClickHouse 노드가 Keeper에 연결 실패

```
Connection refused while connecting to ZooKeeper
```

**원인**: Keeper 설정 파일 경로 불일치 + listen_host 설정 누락

**해결**:
```yaml
# docker-compose.yml
volumes:
  - ./keeper-config.xml:/etc/clickhouse-keeper/keeper_config.xml  # 경로 수정

# keeper-config.xml
<keeper_server>
  <listen_host>0.0.0.0</listen_host>  # 추가
```

---

**문제 2**: 메모리 부족으로 쿼리 실패

```
DB::Exception: Memory limit exceeded
```

**원인**: 16GB 환경에서 여러 서비스 동시 실행 + 데이터 5만 건 이상 축적

**해결**:
1. Flink 중지 (메모리 확보)
2. ClickHouse 메모리 제한 증가 (512MB → 1.5GB)
3. 오래된 데이터 삭제
4. 단일 노드로 운영 전환

**교훈**: 
- 16GB 환경에서 2-shard 클러스터는 부담
- 프로덕션에서는 노드당 최소 8GB 권장
- 개발/학습 환경에서는 단일 노드가 현실적

---

## 5. 시각화: Grafana

### 문제 정의

> "실시간 가격 차트, 주요 지표, 알림을 대시보드로 제공해야 한다"

### 비교 대상

| 기술 | 장점 | 단점 |
|------|------|------|
| **Grafana** | 무료, 플러그인 풍부, ClickHouse 지원 | 커스터마이징 한계 |
| **Metabase** | 비개발자 친화적, 간단한 설정 | 실시간 새로고침 약함 |
| **Apache Superset** | SQL 기반, 다양한 차트 | 설정 복잡, 리소스 많이 사용 |
| **Tableau** | 강력한 시각화 | 유료, 리소스 많이 사용 |
| **Redash** | SQL 친화적, 간단함 | 개발 중단, 기능 제한적 |

### 의사결정 과정

1. **요구사항 정리**:
   - ClickHouse 네이티브 연동 필수
   - 5초 간격 자동 새로고침
   - 알림 기능 (가격 급등락 시)
   - 무료

2. **Grafana 장점**:
   - ClickHouse 공식 플러그인 존재
   - 실시간 대시보드에 최적화
   - 프로비저닝으로 코드 기반 설정 가능
   - 알림 룰 정의 가능

### 최종 결정

```
✅ Grafana (256MB)
```

**이유**:
- ClickHouse 플러그인으로 네이티브 연동
- 실시간 새로고침 (5초)
- YAML 기반 프로비저닝 (GitOps 가능)
- 알림 기능 내장

### 구성

```yaml
grafana:
  image: grafana/grafana:latest
  environment:
    GF_INSTALL_PLUGINS: grafana-clickhouse-datasource
  volumes:
    - ./grafana/provisioning:/etc/grafana/provisioning
    - ./grafana/dashboards:/var/lib/grafana/dashboards
```

### 트러블슈팅

**문제**: Time series 패널에 "Data is missing a time field" 오류

**원인**: Grafana가 시간 필드를 인식하지 못함

**해결**:
```sql
-- 수정 전
SELECT event_time, market, trade_price FROM ...

-- 수정 후
SELECT 
  toDateTime(event_time) as time,  -- 'time'으로 alias 필수
  trade_price
FROM ...
ORDER BY time ASC  -- 오름차순 정렬 필수
```

---

## 최종 아키텍처

```
┌─────────────────┐
│  Upbit WebSocket │
└────────┬────────┘
         │
         ▼
┌─────────────────────────────────────┐
│     Kafka (KRaft, 3 brokers)        │
│  Topics: upbit-ticker, upbit-trade  │
└────────┬────────────────┬───────────┘
         │                │
         ▼                ▼
┌─────────────────┐  ┌─────────────────┐
│  Flink Cluster  │  │   ClickHouse    │
│  (ETL to Paimon)│  │  (Kafka Engine) │
└────────┬────────┘  └────────┬────────┘
         │                    │
         ▼                    ▼
┌─────────────────┐  ┌─────────────────┐
│  MinIO (Paimon) │  │    Grafana      │
│  장기 저장/ML   │  │  실시간 대시보드 │
└─────────────────┘  └─────────────────┘
```

### 데이터 흐름 요약

| 경로 | 용도 | 지연시간 |
|------|------|----------|
| WebSocket → Kafka → ClickHouse → Grafana | 실시간 분석 | < 1초 |
| WebSocket → Kafka → Flink → Paimon | 장기 저장/ML | 30초 (체크포인트) |

### 리소스 사용량

| 서비스 | 인스턴스 | 메모리 | 상태 |
|--------|----------|--------|------|
| Kafka | 3 | 1.5GB | 운영 중 |
| MinIO | 4 | 1GB | 운영 중 |
| ClickHouse | 1 (단일 노드) | 1.5GB | 운영 중 |
| ClickHouse Keeper | 1 | 256MB | 운영 중 |
| Grafana | 1 | 256MB | 운영 중 |
| Flink | 3 | 0 | 중지 (메모리 부족) |
| **합계** | | **~4.5GB** | |

---

## 결론 및 교훈

### 기술 선택 원칙

1. **네이티브 통합 우선**: Kafka-Flink-Paimon은 같은 생태계에서 최적화됨
2. **역할 분리**: 장기 저장(Paimon) vs 실시간 분석(ClickHouse)
3. **리소스 현실 반영**: 16GB에서 모든 것을 분산으로 돌리기 어려움
4. **점진적 복잡도**: 단일 노드 → 클러스터로 확장

### 향후 개선 계획

| 항목 | 현재 | 목표 |
|------|------|------|
| ClickHouse | 단일 노드 | Kubernetes에서 2-shard 클러스터 |
| Flink | 중지됨 | 별도 환경에서 상시 운영 |
| 저장소 | MinIO 로컬 | AWS S3 (프로덕션) |
| 알림 | 미구현 | Grafana Alert + Slack 연동 |

---

## 참고 자료

- [Apache Kafka vs RabbitMQ](https://www.confluent.io/kafka-vs-rabbitmq/)
- [Flink vs Spark Streaming](https://flink.apache.org/flink-vs-spark.html)
- [Paimon vs Iceberg vs Delta Lake](https://paimon.apache.org/docs/master/concepts/overview/)
- [ClickHouse vs TimescaleDB](https://clickhouse.com/docs/en/intro)
