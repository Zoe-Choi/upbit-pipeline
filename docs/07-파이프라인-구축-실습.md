# 7. 업비트 실시간 파이프라인 구축 실습 기록

> 이 문서는 업비트 WebSocket → Kafka → Flink → Paimon(MinIO) 파이프라인을 직접 구축하면서 겪은 과정, 에러, 해결 방법을 정리한 실습 기록입니다.

---

## 목차

1. [완성된 아키텍처](#완성된-아키텍처)
2. [각 컴포넌트의 역할](#각-컴포넌트의-역할)
3. [구축 과정 요약](#구축-과정-요약)
4. [발생한 에러와 해결 방법](#발생한-에러와-해결-방법)
5. [배운 점](#배운-점)
6. [다음 단계](#다음-단계)

---

## 완성된 아키텍처

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  Upbit WebSocket │────▶│  Kafka Cluster  │────▶│  Flink Cluster  │────▶│ Paimon (MinIO)  │
│   (Python)       │     │  (3 Brokers)    │     │ (1 JM + 2 TM)   │     │  (4 Nodes)      │
└─────────────────┘     └─────────────────┘     └─────────────────┘     └─────────────────┘
       │                        │                        │                       │
   실시간 시세            메시지 버퍼링           스트리밍 처리          데이터 레이크
   ticker/trade         토픽 기반 저장          SQL 기반 ETL          Parquet 저장
```

### 현재 상태

| 단계 | 상태 | 설명 |
|------|------|------|
| Upbit WebSocket → Kafka | ✅ 완료 | Python으로 실시간 데이터 수집 |
| Kafka 토픽 | ✅ 완료 | upbit-ticker, upbit-trade 토픽에 데이터 적재 |
| Flink Kafka 소스 | ✅ 완료 | kafka_ticker, kafka_trade 테이블 생성 |
| Flink → Paimon | ✅ 완료 | ticker 테이블에 스트리밍 INSERT |
| MinIO 저장 | ✅ 완료 | s3://paimon/warehouse/upbit.db/ticker |

---

## 각 컴포넌트의 역할

### 1. Python WebSocket 클라이언트 (`src/`)

**역할**: 업비트 WebSocket API에 연결하여 실시간 시세 데이터를 수신하고 Kafka로 전송

```python
# 핵심 흐름
Upbit WebSocket → TickerMessage 파싱 → Kafka Producer → upbit-ticker 토픽
```

**주요 파일**:
- `src/consumers/upbit_websocket.py`: WebSocket 연결, 자동 재연결, 메시지 라우팅
- `src/producers/kafka_producer.py`: Kafka로 메시지 전송 (JSON 직렬화)
- `src/models/ticker.py`: 데이터 모델 정의

**특징**:
- 자동 재연결 (지수 백오프)
- 환경변수 기반 설정 (하드코딩 없음)
- 싱글톤 패턴의 Kafka Producer

---

### 2. Apache Kafka (3 Brokers, KRaft 모드)

**역할**: 실시간 데이터 스트림의 버퍼 및 분산 메시지 큐

```
Producer → [Broker 1] ←→ [Broker 2] ←→ [Broker 3] → Consumer
              │              │              │
           Partition 0    Partition 1    Partition 2
```

**토픽 구성**:
| 토픽 | 파티션 | 복제 계수 | 용도 |
|------|--------|----------|------|
| upbit-ticker | 3 | 3 | 현재가 데이터 |
| upbit-trade | 3 | 3 | 체결 데이터 |
| upbit-orderbook | 3 | 3 | 호가 데이터 |

**왜 Kafka를 사용하는가?**
- 데이터 유실 방지 (복제)
- Consumer 장애 시 재처리 가능 (오프셋 관리)
- 여러 Consumer가 동시에 같은 데이터 소비 가능

---

### 3. Apache Flink (1 JobManager + 2 TaskManager)

**역할**: 스트리밍 데이터 처리 엔진. SQL로 실시간 ETL 수행

```
┌─────────────────────────────────────┐
│           JobManager                │
│  - 작업 스케줄링                     │
│  - 체크포인트 조율                   │
└─────────────────────────────────────┘
         │                    │
┌────────────────┐   ┌────────────────┐
│  TaskManager 1 │   │  TaskManager 2 │
│  - 2 slots     │   │  - 2 slots     │
│  - 실제 처리    │   │  - 실제 처리    │
└────────────────┘   └────────────────┘
```

**Flink SQL의 역할**:

```sql
-- 1. Kafka 소스 테이블: Kafka 토픽을 SQL 테이블처럼 조회
CREATE TABLE kafka_ticker (...) WITH ('connector' = 'kafka', ...);

-- 2. Paimon 싱크 테이블: 데이터 저장소
CREATE TABLE ticker (...) PARTITIONED BY (dt);

-- 3. 스트리밍 잡: 실시간으로 데이터 이동
INSERT INTO ticker SELECT ... FROM kafka_ticker;
```

**왜 Flink를 사용하는가?**
- SQL만으로 스트리밍 처리 가능
- Exactly-once 보장 (체크포인트)
- 윈도우 집계, 조인 등 복잡한 처리 지원

---

### 4. Apache Paimon + MinIO

**역할**: 스트리밍 데이터 레이크. 실시간 데이터를 Parquet 형식으로 저장

```
Flink → Paimon Writer → MinIO (S3)
                          │
                    s3://paimon/warehouse/
                          └── upbit.db/
                                └── ticker/
                                      ├── dt=2026-02-06/
                                      │     └── data-xxx.parquet
                                      └── dt=2026-02-07/
```

**Paimon의 특징**:
| 기능 | 설명 |
|------|------|
| 스트리밍 쓰기 | 실시간으로 데이터 추가 |
| 파티셔닝 | 날짜별로 데이터 분리 |
| ACID 트랜잭션 | 데이터 일관성 보장 |
| Time Travel | 과거 시점 데이터 조회 |
| Merge-on-Read | 업데이트 효율적 처리 |

**MinIO의 역할**:
- S3 호환 오브젝트 스토리지
- 분산 저장 (4노드 Erasure Coding)
- 로컬에서 AWS S3 없이 테스트 가능

---

## 구축 과정 요약

### Step 1: Python 파이프라인 실행

```bash
# 가상환경 생성 (Python 3.10+ 필요)
python3.12 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 파이프라인 실행
python -m src.main
```

### Step 2: Flink 커스텀 이미지 빌드

```dockerfile
# flink/Dockerfile
FROM flink:1.18-scala_2.12-java11

# S3 플러그인 설치 (필수!)
RUN mkdir -p /opt/flink/plugins/s3-fs-hadoop && \
    wget -P /opt/flink/plugins/s3-fs-hadoop/ \
    https://repo1.maven.org/maven2/org/apache/flink/flink-s3-fs-hadoop/1.18.1/flink-s3-fs-hadoop-1.18.1.jar

# Paimon, Kafka 커넥터 설치
RUN wget -P /opt/flink/lib/ paimon-flink-1.18-*.jar && \
    wget -P /opt/flink/lib/ flink-sql-connector-kafka-*.jar
```

```bash
docker compose up -d --build flink-jobmanager flink-taskmanager-1 flink-taskmanager-2
```

### Step 3: Flink SQL로 파이프라인 구성

```bash
# 초기화 스크립트와 함께 SQL Client 시작
docker cp flink-sql/sql-client-init.sql flink-jobmanager:/opt/flink/
docker exec -it flink-jobmanager /opt/flink/bin/sql-client.sh -i /opt/flink/sql-client-init.sql
```

```sql
-- Paimon 테이블 생성
USE CATALOG paimon_catalog;
CREATE DATABASE IF NOT EXISTS upbit;
USE upbit;

CREATE TABLE ticker (...) PARTITIONED BY (dt);

-- 스트리밍 잡 시작
INSERT INTO paimon_catalog.upbit.ticker
SELECT ... FROM default_catalog.default_database.kafka_ticker;
```

---

## 발생한 에러와 해결 방법

### 에러 1: Python 버전 문제

```
ERROR: File "setup.py" or "setup.cfg" not found.
ModuleNotFoundError: No module named 'websockets'
```

**원인**: Python 3.8 + 구버전 pip (21.1.1)

**해결**:
```bash
# Python 3.12 설치
brew install python@3.12

# 새 venv 생성
python3.12 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

---

### 에러 2: Kafka 토픽 `market` 필드 누락

```
Missing required field in message: 'market'
```

**원인**: 업비트 API가 `market` 대신 `code` 필드 사용

**해결**: 모델에서 둘 다 체크하도록 수정
```python
market = data.get("market") or data.get("code")
if not market:
    raise KeyError("market")
```

---

### 에러 3: MinIO 로드밸런서 실패

```
nginx: [emerg] host not found in upstream "minio-1:9000"
```

**원인**: Nginx가 시작할 때 MinIO 컨테이너가 아직 DNS에 등록 안 됨

**해결**: 로드밸런서 대신 직접 `minio-1` 사용
```yaml
s3.endpoint: http://minio-1:9000  # minio-lb 대신
```

---

### 에러 4: Flink Paimon 카탈로그 생성 실패

```
java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration
```

**원인**: Hadoop 관련 JAR 파일 누락

**해결**: 필요한 JAR 파일 설치
```bash
docker exec flink-jobmanager bash -c "
  wget -P /opt/flink/lib/ flink-shaded-hadoop-2-uber-*.jar
"
```

---

### 에러 5: S3 파일시스템 플러그인 없음

```
UnsupportedFileSystemSchemeException: Could not find a file system implementation for scheme 's3'
```

**원인**: Flink의 S3 플러그인은 `/opt/flink/plugins/` 폴더에 설치해야 함

**해결**: Dockerfile로 커스텀 이미지 생성
```dockerfile
RUN mkdir -p /opt/flink/plugins/s3-fs-hadoop && \
    wget -P /opt/flink/plugins/s3-fs-hadoop/ flink-s3-fs-hadoop-1.18.1.jar
```

**핵심 포인트**: 
- `/opt/flink/lib/` → 일반 라이브러리
- `/opt/flink/plugins/s3-fs-hadoop/` → 파일시스템 플러그인 (별도 폴더 필요)

---

### 에러 6: Flink SQL 세션에서 카탈로그 사라짐

```
A catalog with name [paimon_catalog] does not exist.
```

**원인**: Flink SQL Client는 세션 기반. 재접속하면 설정 초기화

**해결**: 초기화 스크립트 사용
```bash
docker exec -it flink-jobmanager /opt/flink/bin/sql-client.sh \
  -i /opt/flink/sql-client-init.sql
```

---

## 배운 점

### 1. 스트리밍 아키텍처 이해

```
데이터 수집 → 메시지 큐 → 스트림 처리 → 데이터 레이크
(Producer)    (Kafka)      (Flink)        (Paimon/MinIO)
```

각 컴포넌트가 **분리**되어 있어서:
- 장애 격리 가능
- 독립적으로 스케일링
- 재처리 용이

### 2. Flink SQL의 강력함

코드 없이 **SQL만으로** 실시간 파이프라인 구축:
```sql
INSERT INTO paimon_table SELECT * FROM kafka_table;
```

### 3. 플러그인 vs 라이브러리

Flink에서:
- `lib/` 폴더: 일반 JAR (Paimon, Kafka 커넥터)
- `plugins/` 폴더: 파일시스템 플러그인 (S3, HDFS)

**플러그인은 반드시 하위 폴더에 배치**해야 함!

### 4. Docker Compose 의존성

`depends_on`은 컨테이너 **시작 순서**만 보장. 서비스가 **준비**될 때까지 기다리지 않음.
→ 헬스체크 또는 수동 대기 필요

### 5. 디버깅 전략

문제 발생 시 확인 순서:
1. `docker compose ps` - 컨테이너 상태
2. `docker compose logs <service>` - 에러 로그
3. 네트워크 연결 테스트 (`curl`, `wget`)
4. 플러그인/JAR 파일 존재 확인

---

## 다음 단계

- [ ] Trade 데이터도 Paimon에 저장
- [ ] 1분봉 OHLCV 집계 (Tumble Window)
- [ ] Kafka → ClickHouse 실시간 적재
- [ ] Grafana 대시보드 구축
- [ ] Kubernetes 배포

---

## 접속 정보 요약

| 서비스 | URL | 용도 |
|--------|-----|------|
| Kafka UI | http://localhost:8080 | 토픽/메시지 모니터링 |
| Flink UI | http://localhost:8081 | 잡 상태 확인 |
| MinIO Console | http://localhost:9001 | 스토리지 확인 |

---

## 프로젝트 파일 구조

```
upbit-pipeline/
├── src/                    # Python 파이프라인
│   ├── main.py
│   ├── consumers/          # WebSocket 클라이언트
│   ├── producers/          # Kafka Producer
│   └── models/             # 데이터 모델
├── flink/
│   └── Dockerfile          # 커스텀 Flink 이미지
├── flink-sql/
│   ├── sql-client-init.sql # 초기화 스크립트
│   └── *.sql               # SQL 스크립트들
├── docker-compose.yml      # 전체 인프라
└── docs/                   # 문서
```
