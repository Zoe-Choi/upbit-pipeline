# 에러 노트: 파이프라인 구축 중 만난 문제들

> 이 문서는 실시간 데이터 파이프라인을 구축하면서 겪은 에러와 해결 과정을 정리합니다.

## 목차

1. [Python 환경](#1-python-환경)
2. [Flink 관련](#2-flink-관련)
3. [MinIO/S3 연동](#3-minios3-연동)
4. [ClickHouse 클러스터](#4-clickhouse-클러스터)
5. [Grafana 시각화](#5-grafana-시각화)

---

## 1. Python 환경

### 1.1 ModuleNotFoundError: No module named 'websockets'

**상황**: Python 스크립트 실행 시 모듈 없음 오류

```bash
ModuleNotFoundError: No module named 'websockets'
```

**원인**: 가상환경 미활성화 또는 의존성 미설치

**해결**:
```bash
# 가상환경 생성 및 활성화
python3 -m venv venv
source venv/bin/activate

# 의존성 설치
pip install -r requirements.txt
```

---

### 1.2 setup.py not found

**상황**: pip install 시 오류

```bash
ERROR: File "setup.py" or "setup.cfg" not found
```

**원인**: Python 버전이 3.10 미만 (레거시 설치 방식 요구)

**해결**:
```bash
# Python 3.10+ 설치 (Homebrew)
brew install python@3.12

# 또는 pyenv 사용
pyenv install 3.12.0
pyenv local 3.12.0
```

---

## 2. Flink 관련

### 2.1 SOURCE 명령어 오류

**상황**: Flink SQL Client에서 SQL 파일 실행 시 오류

```sql
Flink SQL> SOURCE '/path/to/init.sql';
-- 오류: Non-query expression encountered in illegal context
```

**원인**: `SOURCE` 명령어가 DDL 문(CREATE TABLE 등)을 제대로 처리하지 못함

**해결**: 각 SQL 문을 개별적으로 실행하거나, `sql-client-init.sql` 설정 사용

```yaml
# docker-compose.yml
flink-sql-client:
  command: sql-client.sh -i /opt/flink/sql/sql-client-init.sql
```

---

### 2.2 Hadoop Configuration 오류

**상황**: Flink에서 S3 연결 시 오류

```
ClassNotFoundException: org.apache.hadoop.conf.Configuration
```

**원인**: Flink 기본 이미지에 Hadoop 관련 JAR 미포함

**해결**: 커스텀 Flink 이미지 빌드

```dockerfile
FROM flink:1.18-java11

# Hadoop AWS 관련 JAR 추가
COPY hadoop-aws-3.3.4.jar /opt/flink/lib/
COPY aws-java-sdk-bundle-1.12.262.jar /opt/flink/lib/
COPY paimon-flink-1.18-0.9.0.jar /opt/flink/lib/
```

---

### 2.3 S3 FileSystem 스킴 오류

**상황**: Flink에서 MinIO 연결 시 오류

```
UnsupportedFileSystemSchemeException: Could not find a file system 
implementation for scheme 's3'
```

**원인**: S3 플러그인이 `/opt/flink/lib/`가 아닌 `/opt/flink/plugins/`에 있어야 함

**해결**:
```dockerfile
# 플러그인 디렉토리에 배치
COPY flink-s3-fs-hadoop-1.18.1.jar /opt/flink/plugins/s3-fs-hadoop/
```

**핵심 포인트**: Flink는 플러그인과 라이브러리를 분리 관리

```
/opt/flink/lib/       → 일반 라이브러리 (Paimon, Kafka Connector)
/opt/flink/plugins/   → 파일시스템 플러그인 (S3, GCS)
```

---

### 2.4 Paimon 카탈로그 세션 유지

**상황**: SQL Client 재접속 시 카탈로그 없음

```sql
Flink SQL> USE CATALOG paimon_catalog;
-- 오류: A catalog with name [paimon_catalog] does not exist
```

**원인**: Flink 카탈로그는 세션 기반 (영구 저장 아님)

**해결**: 초기화 SQL 파일 사용

```sql
-- sql-client-init.sql
CREATE CATALOG paimon_catalog WITH (
    'type' = 'paimon',
    'warehouse' = 's3://paimon/'
);

USE CATALOG paimon_catalog;
```

```yaml
# docker-compose.yml
command: sql-client.sh -i /opt/flink/sql/sql-client-init.sql
```

---

### 2.5 Paimon 데이터가 안 보임

**상황**: Flink UI에서 데이터 처리 중인데 SELECT 결과 없음

```sql
Flink SQL> SELECT * FROM ticker LIMIT 10;
-- (결과 없음, 무한 대기)
```

**원인**: Paimon은 체크포인트 완료 후에만 데이터 커밋

**해결**: 배치 모드로 확인 또는 충분히 대기

```sql
-- 배치 모드로 전환 (과거 데이터 조회)
SET 'execution.runtime-mode' = 'batch';
SELECT * FROM ticker LIMIT 10;

-- 다시 스트리밍 모드로
SET 'execution.runtime-mode' = 'streaming';
```

**이해 포인트**:
- 스트리밍 모드: 새로운 데이터를 기다림 (무한 대기)
- 배치 모드: 현재까지 커밋된 데이터만 조회

---

### 2.6 Kafka 소스 테이블 데이터 없음

**상황**: `kafka_ticker` 테이블 조회해도 데이터 없음

```sql
SELECT * FROM kafka_ticker LIMIT 5;
-- (무한 대기)
```

**원인**: `scan.startup.mode = 'latest-offset'`으로 설정됨 (새 메시지만 소비)

**해결**: 쿼리 힌트로 과거 데이터부터 읽기

```sql
SELECT * FROM kafka_ticker 
/*+ OPTIONS('scan.startup.mode'='earliest-offset') */
LIMIT 5;
```

---

## 3. MinIO/S3 연동

### 3.1 Nginx 로드밸런서 DNS 오류

**상황**: minio-lb 서비스가 계속 재시작

```
nginx: host not found in upstream "minio-1:9000"
```

**원인**: Docker 내부 DNS 해석 타이밍 이슈

**해결**: 로드밸런서 우회, 직접 연결

```yaml
# Flink 설정에서 직접 minio-1 사용
's3.endpoint' = 'http://minio-1:9000'
```

---

### 3.2 포트 충돌

**상황**: 서비스 재시작 시 포트 바인딩 실패

```
Bind for 0.0.0.0:9000 failed: port is already allocated
```

**원인**: 이전 컨테이너가 완전히 종료되지 않음

**해결**:
```bash
# 모든 관련 컨테이너 완전 정리
docker compose down --remove-orphans

# 또는 특정 포트 사용 프로세스 확인
lsof -i :9000
kill -9 <PID>
```

---

### 3.3 MinIO 버킷 로딩 느림

**상황**: MinIO Web UI에서 paimon 버킷이 계속 로딩 중

**원인**: Paimon이 생성하는 수많은 작은 파일들

**해결**: CLI로 확인 (더 빠름)

```bash
# MinIO Client 설정
docker exec minio-1 mc alias set local http://localhost:9000 admin password

# 버킷 내용 확인
docker exec minio-1 mc ls local/paimon/
docker exec minio-1 mc du local/paimon/
```

---

## 4. ClickHouse 클러스터

### 4.1 설정 파일 오류

**상황**: ClickHouse 노드가 시작 안 됨

```
DB::Exception: checkNoSettingNamesAtTopLevel
```

**원인**: `max_memory_usage` 같은 설정이 잘못된 위치에 있음

**해결**: 메모리 설정을 `users.xml`로 이동

```xml
<!-- clickhouse-config.xml에서 제거 -->
<!-- <max_memory_usage>300000000</max_memory_usage> 제거 -->

<!-- users.xml에 추가 -->
<profiles>
  <default>
    <max_memory_usage>1000000000</max_memory_usage>
    <max_memory_usage_for_user>1200000000</max_memory_usage_for_user>
  </default>
</profiles>
```

---

### 4.2 Keeper 연결 실패

**상황**: ClickHouse 노드가 Keeper에 연결 못함

```
Coordination::Exception: Connection refused while connecting to ZooKeeper
nodes: 172.21.0.4:9181
```

**원인 1**: Keeper 설정 파일 마운트 경로 불일치

```yaml
# 잘못된 경로
- ./keeper-config.xml:/etc/clickhouse-keeper/config.xml

# 올바른 경로
- ./keeper-config.xml:/etc/clickhouse-keeper/keeper_config.xml
```

**원인 2**: Keeper가 localhost만 리스닝

```xml
<!-- keeper-config.xml -->
<keeper_server>
  <tcp_port>9181</tcp_port>
  <!-- 이 줄 추가 필수 -->
  <listen_host>0.0.0.0</listen_host>
</keeper_server>
```

**해결 후 재시작**:
```bash
docker compose down
docker volume rm upbit-pipeline_clickhouse_keeper_data
docker compose up -d clickhouse-keeper clickhouse-1 clickhouse-2
```

---

### 4.3 메모리 부족 오류

**상황**: 쿼리 실행 시 메모리 초과

```
DB::Exception: Memory limit exceeded: would use 631.33 MiB,
maximum: 921.60 MiB. (MEMORY_LIMIT_EXCEEDED)
```

**원인**: 16GB 맥북에서 여러 서비스 동시 실행 + 데이터 과다 축적

**해결**:

1. **단기 해결**: 불필요한 서비스 중지
```bash
docker compose stop flink-jobmanager flink-taskmanager-1 flink-taskmanager-2
```

2. **메모리 제한 증가**:
```yaml
# docker-compose.yml
clickhouse-1:
  deploy:
    resources:
      limits:
        memory: 1536M  # 512M → 1536M
```

3. **오래된 데이터 삭제**:
```sql
ALTER TABLE upbit.ticker_local DELETE 
WHERE event_time < now() - INTERVAL 10 MINUTE;
```

4. **단일 노드 운영**:
```bash
docker compose stop clickhouse-2
# Grafana에서 ticker_local 테이블 직접 쿼리
```

**교훈**: 
- 16GB 환경에서 2-shard ClickHouse 클러스터는 무리
- 프로덕션에서는 노드당 최소 8GB 권장
- 개발 환경에서는 단일 노드가 현실적

---

## 5. Grafana 시각화

### 5.1 데이터소스 저장 실패

**상황**: ClickHouse 데이터소스 저장 시 오류

```
[handshake] unexpected packet [72] from server
```

**원인**: Native 프로토콜(9000)로 HTTP 요청 시도

**해결**: HTTP 프로토콜 사용

```
Protocol: HTTP
Server address: clickhouse-1
Port: 8123 (HTTP 포트, 9000이 아님)
```

---

### 5.2 Time series 시간 필드 오류

**상황**: 차트에 "Data is missing a time field" 오류

```
Data is missing a time field
```

**원인**: Grafana가 시간 필드를 인식하지 못함

**해결**: 시간 컬럼을 `time`으로 alias

```sql
-- 수정 전
SELECT event_time, trade_price FROM ...

-- 수정 후
SELECT 
  toDateTime(event_time) as time,  -- 'time' alias 필수
  trade_price
FROM ...
```

---

### 5.3 시간순 정렬 오류

**상황**: 차트에 데이터가 안 뜸

```
Unable to process the data because it is not sorted in ascending order by time
```

**원인**: Time series 패널은 시간 오름차순 정렬 필요

**해결**:
```sql
SELECT 
  toDateTime(event_time) as time,
  trade_price
FROM upbit.ticker_local
WHERE market = 'KRW-BTC'
ORDER BY time ASC  -- 오름차순 정렬 필수
```

---

### 5.4 시리즈 구분 안 됨

**상황**: 여러 코인이 하나의 선으로 표시

**원인**: Grafana가 market 컬럼으로 시리즈 분리를 못함

**해결**: 각 코인별 별도 쿼리

```json
{
  "targets": [
    {
      "rawSql": "SELECT toDateTime(event_time) as time, trade_price as BTC FROM ... WHERE market = 'KRW-BTC'",
      "refId": "BTC"
    },
    {
      "rawSql": "SELECT toDateTime(event_time) as time, trade_price as ETH FROM ... WHERE market = 'KRW-ETH'",
      "refId": "ETH"
    }
  ]
}
```

---

## 핵심 교훈 정리

| 카테고리 | 교훈 |
|----------|------|
| **리소스** | 16GB에서 분산 시스템 모두 돌리기 어려움, 우선순위 결정 필요 |
| **Flink** | 플러그인 vs 라이브러리 경로 구분 중요 |
| **Paimon** | 체크포인트 후에만 데이터 보임, 스트리밍/배치 모드 이해 필요 |
| **ClickHouse** | 설정 파일 위치/형식에 민감, Keeper listen_host 필수 |
| **Grafana** | 시간 필드 'time' alias + ASC 정렬 필수 |

---

## 디버깅 체크리스트

### 서비스가 안 뜰 때
```bash
# 로그 확인
docker compose logs <service-name>

# 헬스체크 상태
docker compose ps

# 컨테이너 내부 확인
docker exec -it <container> sh
```

### 데이터가 안 보일 때
```bash
# Kafka 메시지 확인
docker exec kafka-1 kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic upbit-ticker --from-beginning --max-messages 5

# ClickHouse 데이터 확인
docker exec clickhouse-1 clickhouse-client \
  --query "SELECT count() FROM upbit.ticker_local"
```

### 메모리 부족할 때
```bash
# 메모리 사용량 확인
docker stats

# 불필요한 서비스 중지
docker compose stop <service-name>

# 볼륨 정리
docker system prune -a --volumes
```
